# yahoo_streaming_benchmark_experiment

This repository consists of a Kafka event generator and a Flink processor. The code is adapted from the [Yahoo streaming benchmark](https://github.com/yahoo/streaming-benchmarks) (blog post [here](https://yahooeng.tumblr.com/post/135321837876/benchmarking-streaming-computation-engines-at)).

In this advertising use case, ad events are generated by a Kafka producer in a JSON format. The events are parsed, filtered for the ad "view" events, unneeded fields are removed, and new fields are added by joining the event with campaign data stored in Redis. Views are then aggregated by campaign and by time window and stored back into Redis, along with a timestamp to indicate when they are updated.

## Setup
Use [Maven](https://maven.apache.org) to create executable jars for the Kafka producer and Flink processor.

Experiments require Zookeeper, Kafka, Redis, HDFS, and Flink to be running.

## Configuration

Configurations need to be specified for both the Kafka producer and Flink processor.

Producer: producer/src/main/resources/producer.properties

Processor: processor/src/main/resources/processor.properties

After specifying the configurations, create jars for the producer and processor by running ``mvn clean && mvn package`` in the root directory

## Event generator

Events are generated according to the configured csv file in processor.properties

Start the producer with:

```bash
java -jar producer/target/producer-1.0-SNAPSHOT.jar
```

## Flink processor

The "processor-1.0-SNAPSHOT.jar" can be submitted to the Flink cluster via the Flink dashboard or by running:
```bash
flink run processor/target/processor-1.0-SNAPSHOT.jar [checkpoint interval (ms)]
```
The processor expects the checkpoint interval in milliseconds as an argument.

Note: The number of task managers must be greater or equal to the number of Kafka partitions specified in the configuration file.
